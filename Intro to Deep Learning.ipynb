{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "781931c7",
   "metadata": {},
   "source": [
    "# INTRO TO DEEP LEARNING (MIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe0708",
   "metadata": {},
   "source": [
    "### LECTURE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63631848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf #importing tensorflow package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "366257ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntf.math.sigmoid(z)\\ntf.math.tanh(z)\\ntf.nn.relu(z)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#few Non linear activation functions: \n",
    "\"\"\"\n",
    "tf.math.sigmoid(z)\n",
    "tf.math.tanh(z)\n",
    "tf.nn.relu(z)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4fa86d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense Layer:\n",
    "\n",
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        \n",
    "        self.w=self.add_weight([input_dim,output_dim])\n",
    "        self.b=self.add_weight([1,output_dim])\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        z=tf.matmul(inputs, self.w)+self.b\n",
    "        output=tf.math.sigmoid(z)\n",
    "        \n",
    "        return output\n",
    "                #OR\n",
    "        \n",
    "layer= tf.keras.layers.Dense(units=2) #units--> no. of output units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee0cccbc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m      5\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(n),       \u001b[38;5;66;03m#n hidden units in the hidden layer\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m2\u001b[39m)        \u001b[38;5;66;03m#2 output units \u001b[39;00m\n\u001b[0;32m      7\u001b[0m ])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#For multiple hidden layers, we stack each one of them>>\u001b[39;00m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m---> 11\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[43mn1\u001b[49m),\n\u001b[0;32m     12\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(n2),\n\u001b[0;32m     13\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(n3),\n\u001b[0;32m     14\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m2\u001b[39m) \n\u001b[0;32m     15\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n1' is not defined"
     ]
    }
   ],
   "source": [
    "#Sequential Model:\n",
    "\n",
    "#For one hidden layer:\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(n),       #n hidden units in the hidden layer\n",
    "    tf.keras.layers.Dense(2)        #2 output units \n",
    "])\n",
    "\n",
    "#For multiple hidden layers, we stack each one of them>>\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(n1),\n",
    "    tf.keras.layers.Dense(n2),\n",
    "    tf.keras.layers.Dense(n3),\n",
    "    tf.keras.layers.Dense(2) \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5811063a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Loss functions:\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m loss\u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax_cross_entropy_with_logits(\u001b[43my\u001b[49m,pred))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "#Loss functions:\n",
    "\n",
    "loss= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y,pred)) #binary cross entropy for binary classification\n",
    "\n",
    "loss=tf.reduce_mean(tf.square(tf.subtract(y,pred)))\n",
    "loss=tf.keras.losses.MSE(y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9684ef1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Received: layer=Ellipsis of type <class 'ellipsis'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Training the NN, using Gradient Descent:\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD() \u001b[38;5;66;03m#can pick any optimizer in tensorflow\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\users\\sai anish\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    589\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\sai anish\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\users\\sai anish\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\sequential.py:178\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    176\u001b[0m     layer \u001b[38;5;241m=\u001b[39m functional\u001b[38;5;241m.\u001b[39mModuleWrapper(layer)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe added layer must be an instance of class Layer. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    179\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived: layer=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(layer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    181\u001b[0m tf_utils\u001b[38;5;241m.\u001b[39massert_no_legacy_layers([layer])\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_layer_name_unique(layer):\n",
      "\u001b[1;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Received: layer=Ellipsis of type <class 'ellipsis'>."
     ]
    }
   ],
   "source": [
    "#Training the NN, using Gradient Descent:\n",
    "\n",
    "model = tf.keras.Sequential([...])\n",
    "\n",
    "optimizer=tf.keras.optimizers.SGD() #can pick any optimizer in tensorflow\n",
    "while True:\n",
    "    pred = model(x) #forward passing thru the network\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss= compute_loss(y,pred) #computing the loss\n",
    "    grads=tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8c33ea7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Regularization\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#1:\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'rate'"
     ]
    }
   ],
   "source": [
    "#Regularization\n",
    "#1:\n",
    "tf.keras.layers.Dropout(p=0.5) #drops 50% of activations in a layer\n",
    "#2:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa5005",
   "metadata": {},
   "source": [
    "### LECTURE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea7a7f29",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#RNN intuition:\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m myrnn\u001b[38;5;241m=\u001b[39m\u001b[43mRNN\u001b[49m()\n\u001b[0;32m      4\u001b[0m hidden_state\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m sentence\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlove\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecurrent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneural\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RNN' is not defined"
     ]
    }
   ],
   "source": [
    "#RNN intuition:\n",
    "\n",
    "myrnn=RNN()\n",
    "hidden_state=[0,0,0,0]\n",
    "sentence= [\"I\",\"love\",\"recurrent\",\"neural\"]\n",
    "\n",
    "for word in sentence:\n",
    "    pred, hidden_state=myrnn(word,hidden_state)\n",
    "next_word_pred=pred\n",
    "#<<networks>> is given as output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8435266f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rnn_units' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#implementing RNN using tf\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mSimpleRNN(\u001b[43mrnn_units\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rnn_units' is not defined"
     ]
    }
   ],
   "source": [
    "#implementing RNN using tf\n",
    "tf.keras.layers.SimpleRNN(rnn_units) #rnn_units--> no. of recurrent cells if im not wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4080fe7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_units' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#implementing LSTM using tf\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTM(\u001b[43mnum_units\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_units' is not defined"
     ]
    }
   ],
   "source": [
    "#implementing LSTM using tf\n",
    "tf.keras.layers.LSTM(num_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1538dd75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
